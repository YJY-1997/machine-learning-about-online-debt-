 # **基于机器学习算法的网络信贷风险评估**

<font color=grey>***注：本文源自笔者 2020年本科毕业论文，已收录在兰州大学图书馆。本文旨在分享学习，请勿作他用。***</font>

## 项目简介

项目旨在利用机器学习算法，试图通过对平台现有数据的分析，对借贷交易进行预测，判断借款客户违约还款的可能性，为相关网络平台提供借鉴方案，以此减少平台与客户的潜在损失，维护网络贷款交易的安全性 . 

首先使用 Python 爬虫从 P2P 网贷平台上获取了 1726 条借贷数据，其中违约数据 571 条，未违约数据 1155 条。接着使用了**决策树、支持向量机，线性判别分析**来处理网贷违约与否的二分类问题，并且**创新性的对线性判别分析法进行了改进**，提升了模型性能 .  

相关代码使用 Python 语言进行编写，采用十折交叉验证法训练模型，对借款人会否违约进行预测，最终通过 4 种模型的对比，发现**改进后的线性判别分析法是处理网贷违约风险预测的最佳分类决策方案 .** 

项目相关结论如下：**还款期限、年利率、还清笔数、信用额度**等特征对违约预测有相当程度的影响，特别是**还款期限 30 月以内，年利率高于 10.9% 的借贷交易很可能发生违约.** 与之相反，性别、学历和房贷对违约的影响很小 . 



## **目	录**

一、绪 论	

* 研究背景	

* 研究现状	

二、相关算法理论	

* 线性判别分析	
  * 协方差
  * 线性判别分析

* 决策树	
  * 算法思想	
  * 经典算法	

* 支持向量机	

* 评价指标	

三、数据来源和处理	

* 数据来源	

* 数据处理	

四、实证分析	

* PCA	

* 模型应用	
  * 线性判别分析	
  * 决策树	
  * 支持向量机	
  * LDA算法改进	

* 模型性能对比	

五、总 结	

参考文献	



## 一、绪	论

### **研究背景**

P2P 网络信贷作为传统金融行业与新兴互联网+时代的产物，在信息技术不断发展的潮流下，逐渐展现出了吸引力与生命力. P2P 平台是个人对个人借贷的衔接渠道，在这里，有资金需求的企业主会发布借款申请，而有闲置资金的个人投资者可在衡量对方企业经营水平、偿贷能力等后提供借款. 

2005 年 3 月，理查德·杜瓦、詹姆斯·亚历山大、萨拉·马休斯和大卫·尼克尔森等 4 位英国人创办了全球第一家 P2P 网贷平台 Zopa，这也是 P2P 网贷模式的雏形. 2007 年，国外网络借贷平台模式引入了中国，对我国传统借贷模式发起了有力冲击，国内 P2P 网贷模式开始兴起，截止 2020 年 5 月，仅“[网贷之家](https://www. wdzj. com/dangan/)"一家网站已收录网贷平台达6607 家. 如今，我国网贷发展已先后经历了以信用借款为主的初始发展期、以地域借款为主的快速扩张期、以自融高息为主的风险爆发期、以规范监管为主的政策调整期等 4 个阶段,现在，正以国内市场为基础试图向海外市场拓展，以谋求更广阔的发展空间.

目前，网贷平台上的融资项目年利率在 10% 左右，高于大部分银行理财产品，高额的收益率正是近年来网贷发展壮大的重要原因之一. 作为新一代借贷模式，P2P 网贷挣脱了传统借贷的框架，在时间与空间上更加自由，用户可以更加方便，更加快捷的通过网贷平台进行借贷交易. 一次完整的网贷交易流程，如：认证、记账、清算等过程，均可通过网络完成，使得借贷双方足不出户即可完成资金周转流通. 凭借网贷的高收益性、便捷性，近年来，P2P 网贷蓬勃发展，很多借贷机构着手进入网贷领域. 

然而，网贷是一把双刃剑，在给人们带来方便的同时，也暴露出了一些安全隐患，甚至引起了一些社会乱象. 在便利的背后隐藏着的是网贷模式的不成熟性，网贷的便捷性同时也带来了无抵押交易的高风险性，有心之人利用网贷制度尚不健全的漏洞，在相关平台上实施欺诈，进行“骗贷”，为自己谋取非法利益，给网贷机构、贷款人带来了巨大损失. 同时，缺乏有效的监管手段也是缺陷之一. 尽管网贷平台层出不穷，却也略显杂乱无章，如何对网贷进行更好、更全面的监督管理，如何建立健全网贷机制、保障人民利益，现已成为了当下的一大话题. 目前，市场监管的力度正在加大，多项政策的出台遏制了网贷发展趋势，但离全面的保障机制仍有一段距离. 目前，在相关部门的有力管控下，在“网贷之家”收录的平台中，停业及转型平台 3346 家，问题平台 2929 家，而正常运营平台仅有 332 家. 大量的不合格、小规模平台是网贷乱象的主要根源之一. 

本文立足于上述现象，试图通过对平台现有数据的分析，对借贷交易进行预测，判断借款客户违约还款的可能性，为相关网络平台提供借鉴方案，以此减少平台与客户的潜在损失，维护网络贷款交易的安全性. 

 

### **研究现状**

随着计算机技术的蓬勃发展，机器学习在科学进步中起到了不可磨灭的作用. 机器学习以其运算速度及对海量数据的智能化处理受到了人们的广泛关注与青睐. 运用机器学习算法初步解决网络信贷的风险预测问题应当是一个可取、高效的方法. 

在此之前，已有许多学者运用机器学习知识对 P2P 网贷进行了多方位研究. 王梦雪 (2017) 在大数据背景下，对风控模型进行研究，使用随机森林、GBDT、XGBoost 等集成方法，得出机器学习预测模型优于传统风控模型的结论；罗雅晨 (2018) 针对网贷违约与不违约类别不平衡问题，通过比较 4 个单模型，8 个集成学习模型，发现比例平衡的随机森林模型性能最优；吴艇帆 (2019) 对 Lending Club 数据进行正则化 Logistic 回归建模，得出 L1 正则化能够较好制衡借款人信息在模型中的权重，生成的模型可以取得不错分类效果；李汛，龙真等 (2019) 采用 CART 决策树、SVM 和 K-邻近算法根据人人贷数据进行违约预测，发现借款年利率、借款期限、贷款额度、抵押品价格等因素对违约有较大影响. 

目前多数研究主要采用了 Logistic 回归、决策树、随机森林、Boosting 等算法，大致思路为先使用基本分类器对数据进行初步预测，根据模型精度选择是否使用集成学习方法将基本分类器提升为强分类器，增强模型预测性能，得到更好的预测方案. 

在参考前人研究成果的基础上，本文除了使用了决策树、支持向量机，还引入了线性判别分析来处理网贷违约与否的二分类问题，从人人贷网贷平台上爬取数据，使用 Python 语言进行编程，采用十折交叉验证法训练模型，对借款人会否违约进行预测，最终通过 3 种模型的对比，选出最佳分类决策方案. 

 

## **二、相关算法理论**

### **线性判别分析**

#### **协方差**

给定样本集 $D=\{(x_1,\ y_1),\ (x_2,\ y_2),...,\ (x_m,\ y_m)\},\ y\in\{0,\ 1\}$，$x_i$ 为第 $ i $ 个样本，$y_i$ 为 $x_i$ 的类别标记，构造矩阵 $X=(x_1,\ x_2,\ ...,\ x_n)$，将样本的 $n$ 个特征均看作随机变量，则第 $i$ 个特征的观测值的集合构成 $X$ 的行向量 $\beta_i,\ i=1,2,...,n$，即 $X=(\beta_1;\ \beta_2;\ ...\ \beta_n;)$，第 $k$ 个样本的第 $i$ 个分量可以表示为 $x_{ik}$ 或 $\beta_{ik}$, $k=1,2,...,m$，则 $\beta_i,\ \beta_j$ 之间的协方差为
$$
cov(\beta_i,\ \beta_j)=\frac{1}{m-1}\sum_{k=1}^{m}{(\beta_{ik}-\overline{\mu_i})(\beta_{jk}-\overline{\mu_j})}=\frac{1}{m-1}(\beta_{i}-{\mu_i})(\beta_{j}-{\mu_j})^T.\tag{2.1}
$$
其中，$\overline{\mu_i}$ 为 $\beta_i$ 的期望，$\mu_i=(\overline{\mu_i})_{1\times m}=(\overline{\mu_i},\ \overline{\mu_i},\ ...,\ \overline{\mu_i})$. 样本任意两个特征之间的协方差构成了协方差矩阵 $\Sigma$，称 $\Sigma$ 为 $D$ 中样本的协方差矩阵
$$
\Sigma=\left(\begin{matrix}cov(\beta_1,\beta_1)&cov(\beta_1,\beta_2)&...&cov(\beta_1,\beta_n)\\cov(\beta_2,\beta_1)&cov(\beta_2,\beta_2)&...&cov(\beta_2,\beta_n)\\...&&&...\\cov(\beta_n,\beta_1)&cov(\beta_n,\beta_2)&...&cov(\beta_n,\beta_n)\\\end{matrix}\right)\tag{2.2}
$$
将式 $(2.1)$ 代入式 $(2.2)$，并令均值向量 $\mu=(\overline{\mu_1};\ \overline{\mu_2};\ ...;\ \overline{\mu_n};)^T$，则
$$
\begin{aligned}\Sigma&=\frac{1}{m-1}\sum_{k=1}^{m}\left(\begin{matrix}(\beta_{1k}-\overline{\mu_1})(\beta_{1k}-\overline{\mu_1})&...&...&(\beta_{1k}-\overline{\mu_1})(\beta_{nk}-\overline{\mu_n})\\...&&&...\\...&&&...\\(\beta_{nk}-\overline{\mu_n})(\beta_{1k}-\overline{\mu_1})&...&...&(\beta_{nk}-\overline{\mu_n})(\beta_{nk}-\overline{\mu_n})\end{matrix}\right)\\&=\frac{1}{m-1}\sum_{k=1}^{m}{(x_k-\mu)(x_k-\mu)^T}\end{aligned}\tag{2.3}
$$


#### **线性判别分析**

线性判别分析 ( Linear Discriminant Analysis，简称 LDA ) 是对 Fisher 的线性鉴别方法的归纳，是一种经典的线性学习方法. 该方法可用于解决二分类问题，现在也常用作对高维样本的监督降维. LDA 用于二分类时，其主要思想是试图将所有样本投影到一条直线上，使得不同类样本点尽量远离，同类别的样本点尽量接近. 找到这条直线后，对所有待预测的样本，都将其投影至该直线上，再根据投影的位置判断样本的类别. 

在获得数据集 $D=\{(x_1,y_1),\ (x_2,y_2),\ ...,\ (x_m,y_m)\},\ y\in\{0,\ 1\}$ 后，令 $X_i,\ \mu_i,\ \Sigma_i,\ i\in\{0,\ 1\}$ 表示第 $i$ 类的集合、均值向量、协方差矩阵，$\omega$ 为目标直线. 为使同类样本投影点相近，异类投影点相离，应使同一类样本投影点在直线 $\omega$ 上的方差 $\Sigma$ 尽量小，不同类样本投影中心的距离 $d$ 尽量大. 定义 $J$ 
$$
\begin{aligned}J&=\frac{d}{\Sigma}=\frac{||\omega^T\mu_0-\omega^T\mu_1||_2^2}{\omega^T\Sigma_0\omega+\omega^T\Sigma_1\omega}\\&=\frac{\omega^T(\mu_0-\mu_1)(\mu_0-\mu_1)^T\omega}{\omega^T(\Sigma_0+\Sigma_1)\omega}\end{aligned}\tag{2.4}
$$
我们需要求出使得 $J$ 最大的 $\omega$ ，即
$$
\omega=arg\max_{\omega}J=arg\max_{\omega}\frac{\omega^T(\mu_0-\mu_1)(\mu_0-\mu_1)^T\omega}{\omega^T(\Sigma_0+\Sigma_1)\omega}\tag{2.5}
$$
由于分子分母都是关于 $\omega$ 的二次项，从而式 $(2.4)$ 的解与 $||\omega||$ 无关，仅与 $\omega$ 方向有关. 不妨令 $\omega^T(\Sigma_0+\Sigma_1)\omega=1$ ，则问题转化为
$$
\min_{\omega}{[-\omega^T(\mu_0-\mu_1)(\mu_0-\mu_1)^T\omega\ ]}\\s.t.\ \ \omega^T(\Sigma_0+\Sigma_1)\omega=1\tag{2.6}
$$
对式 $(2.6)$ 使用拉格朗日乘子法，进一步地，因为 $(\mu_0-\mu_1)^T\omega$ 为实数，不妨令 $(\mu_0-\mu_1)(\mu_0-\mu_1)^T\omega=\lambda(\mu_0-\mu_1)$ ，可得
$$
\omega=(\Sigma_0+\Sigma_1)^{-1}(\mu_0-\mu_1)\tag{2.7}
$$
这里假设了各类样本的协方差矩阵满秩. 在得到目标直线后，LDA 将测试集样本投影至该直线上，并把聚集在一起的投影点分为一类，最终得到预测结果. 

LDA 的不足之处在于若直线上两类别的距离较近，该方法对于处在两类边界的投影点的归类有些模糊，容易分类出错. 但总体来说 LDA 能够较准确找到对数据集进行有效分类的方向，而它的另一个用途——样本降维，如今被广泛应用于数据预处理，为复杂样本的处理提供了有力工具. 将 LDA 推广到 N 分类后，该方法可以将样本维数从高维降至最多 N-1 维，大大简化了模型复杂度. 

 

### **决策树**

#### **算法思想**

决策树 (decision tree) 是一种应用广泛的分类与回归机器学习方法，最早于 1962 年由 E. B. Hunt 提出. 他的学生 Quinlan 推广了导师的思想，并先后提出了著名的 ID3、C4. 5 算法. 决策树采用“分而治之”的策略，树的生成是一个递归过程. 在给定数据集 $D=\{(x_1,\ y_1),\ (x_2,\ y_2),...,\ (x_m,\ y_m)\},\ y\in\{0,\ 1\}$ 与非空样本特征集合 $\beta=(\beta_1,\ \beta_2,\ ...,\ \beta_n)$ 后，算法主要思想为：

1. 将数据集 $D$ 作为树 $T$ 根结点；
2. 若 $D$ 中样本在 $\beta$ 上取值相同，则将根节点标记为叶节点，其类别标记为 $D$ 中样本数最多的类，树生成完毕；否则，进入3；

3. 从 $\beta$ 中选择最优划分特征 $\beta_*$ ，并对 $\beta_*$ 的每一个可能值 $b_i$，依 $\beta_*=b_i$ 将 $D$ 分割为若干非空子集 $D_i$ ，将 $D_i$ 中样本数最多的类作为标记，构建子结点；

4. 根结点与所有子结点构成树 $T$；

5. 对第 $i$ 个子结点，以 $D_i$ 为数据集，以 $\beta-\{\beta_*\}$ 为特征集，重复 1 至 4 ，生成子树 $T_i$ ，将 $T_i$ 与其父结点拼接. 

上述过程的关键在于最优划分特征如何选出以及子树的生成何时停止. 对于第一点，我们引入信息增益、信息增益比和基尼指数三个指标来筛选特征；对于第二点，通常子树生成会进行至特征集只含一个元素或某一子结点中样本均为同一类别为止，但这常常会导致过拟合问题，因此我们引入决策树生成过程中的 “ 预剪枝 ” 和决策树生成后的 “ 后剪枝 ” 策略来对树的分支进行简化. 

 

#### **经典算法**

经典的决策树算法有 ID3、C4. 5 和 CART 算法. ID3 与 C4. 5 中涉及了熵的概念. 给定数据集 $D$ 和特征 $\beta_i$，设样本共有 $N$ 个类 $C_k,\ k=1,2,...,N$ ，设特征 $\beta_i$ 有 $n$ 个不同的可能值 $\{b_1,\ b_2,\ ...,\ b_n\}$，根据 $\beta_i$ 的取值将 $D$ 划分为 $n$ 个子集 $D_1,\ D_2,\ ...,\ D_n$，子集 $D_i$ 中属于类 $C_k$ 的样本集合记为 $D_{ik}$. 数据集 $D$ 的熵定义为
$$
H(D)=-\sum_{k=1}^{N}{\frac{|C_k|}{|D|}\log_2{\frac{|C_k|}{|D|}}}\tag{2.8}
$$
特征 $\beta_i$ 对数据集 $D$ 的条件熵为
$$
H(D|\beta_i)=\sum_{i=1}^{n}\frac{|D_i|}{|D|}H(D_i)=-\sum_{i=1}^{n}\frac{|D_i|}{|D|}\sum_{k=1}^{N}{\frac{|D_{ik}|}{|D_i|}\log_2{\frac{|D_{ik}|}{|D_i|}}}\tag{2.9}
$$
特征 $\beta_i$ 对数据集 $D$ 的信息增益定义为
$$
g(D,\ \beta_i)=H(D)-H(D|\beta_i)\tag{2.10}
$$
特征 $\beta_i$ 对数据集 $D$ 的信息增益比定义为
$$
g_R(D,\ \beta_i)=\frac{g(D,\ \beta_i)}{H_{\beta_i}(D)}\\H_{\beta_i}(D)=-\sum_{i=1}^{n}\frac{|D_i|}{|D|}\log_2\frac{|D_i|}{|D|}\tag{2.11}
$$
其中，$H_{\beta_i}(D)$ 为数据集 $D$ 关于特征 $\beta_i$ 的值的熵. 每次结点的划分选择信息增益 (ID3) 或信息增益比 (C4. 5) 最大的特征作为最优划分特征. 而 CART 算法则使用基尼指数作为指标. 对于 N 分类问题，$C_k$ 是数据集 $D$ 中属于第 $k$ 类的样本子集，$D$ 的基尼指数为
$$
Gini(D)=1-\sum_{k=1}^{N}(\frac{|C_k|}{|D|})^2\tag{2.12}
$$
在特征 $\beta_i$ 的条件下，集合 $D $ 的基尼指数定义为
$$
Gini(D,\beta_i)=\frac{|D_1|}{|D|}Gini(D_1)+\frac{|D_2|}{|D|}Gini(D_2)\tag{2.13}
$$
其中 $D_1$为特征 $\beta_i=b$ ( $b$ 为 $\beta_i$ 某一可能值 ) 的所有样本的集合，$D_2$ 是 $D_1$ 的关于 $D$ 的补集.  CART 每次选择使得基尼指数最小的特征作为最优特征. 

 

### **支持向量机**

支持向量机 (support vector machines,简称SVM) 是一种有监督的学习模型，可用于分类和回归问题.  Vapnik 在 1963 年首次提出了支持向量这一概念，之后不断完善形成了 SVM 的雏形.  SVM 基于结构风险最小化原则，在特征空间中构建最优超平面，使得学习器得到全局最优化，换句话说，SVM 试图在数据集的特征空间中求解一个能够正确划分训练数据集的超平面并尽量使得两类样本到超平面的最小距离最大化. 

假设超平面 $\Gamma$ 方程为：
$$
\omega^Tx+b=0\tag{2.14}
$$
其中 $\omega=(\omega_1;\ \omega_2;\ ...;\ \omega_n;)$ 为超平面法向量，$b$ 为截距项. 

给定样本集 $D=\{(x_1,y_1),\ (x_2,y_2),\ ...,\ (x_m,y_m)\},\ y\in\{-1,\ 1\}$ ，如果超平面 $\Gamma$ 能将不同类的样本完全划分开，即对于 $\forall\ (x_i,\ y_i)\in D$，若 $y_i=+1$ ，有 $\omega^Tx+b>0$ ；若 $y_i=-1$ ，有 $\omega^Tx+b<0$ ，此时我们称样本在特征空间中是线性可分的. 那么样本点 $x_i$ 到超平面 $\Gamma$ 的距离为
$$
d_i=\frac{|\omega^Tx_i+b|}{||\omega||}=\frac{y_i(\omega^Tx_i+b)}{||\omega||}\tag{2.15}
$$
为使不同类样本到超平面的最小距离最大化，问题转化为以下最优化问题：
$$
\max_{\omega,\ b}d\\s.t.\ \ \frac{y_i(\omega^Tx_i+b)}{||\omega||}\geq d,\ i=1,2,...,m\tag{2.16}
$$
令 $\gamma=\min y_i(\omega^Tx_i+b)$ ，则式 $(2.16)$ 等价于
$$
\max_{\omega,\ b}\frac{\gamma}{||\omega||}\\s.t.\ \ {y_i(\omega^Tx_i+b)}\geq \gamma,\ i=1,2,...,m\tag{2.17}
$$
通过等比例缩放 $\omega,\ b$ 可以使得 $\gamma=1$ ，且并不影响目标函数的优化. 同时，注意到最大化 $||\omega||^{-1}$ 等价于最小化 $\frac{1}{2}||\omega||^2$ ，于是式 $(2.17)$ 可重写为
$$
\max_{\omega,\ b}\frac{1}{2}||\omega||^2\\s.t.\ \ {y_i(\omega^Tx_i+b)}\geq 1,\ i=1,2,...,m\tag{2.18}
$$
由拉格朗日乘子法及对偶性，得到式 $(2.18)$ 的对偶问题
$$
\max_{\alpha}\sum^{m}_{i=1}\alpha_i-\frac{1}{2}\sum_{i=1}^{m}\sum_{j=1}^{m}\alpha_i\alpha_jy_iy_jx_i^Tx_j\\s.t.\ \ \sum_{i=1}^{m}\alpha_iy_i=0,\ \alpha_i\geq0,\ i=1,2,...,m\tag{2.19}
$$
求出 $\alpha$ 后，再根据
$$
\omega=\sum_{i=1}^{m}\alpha_iy_ix_i\\b=y_i-\sum_{i=1}^{m}\alpha_iy_ix_i^Tx_j\tag{2.20}
$$
最终得到分类决策函数：
$$
f(x)=sign(\omega^Tx+b)\tag{2.21}
$$
其中上述最优化问题应满足 KKT 条件：
$$
\begin{cases}\alpha_i\geq0;\\y_if(x_i)-1\geq0;\\
\alpha_i(y_if(x_i)-1)=0.\end{cases}\tag{2.22}
$$
当样本线性不可分时，通过加上松弛变量改变目标函数与约束条件为
$$
\frac{1}{2}||\omega||^2+C\sum_{i=1}^{m}\xi_i\\y_i(\omega^Tx_i+b)\geq1-\xi_i,\ i=1,2,..,m\tag{2.23}
$$
进行求解. 若效果仍不理想，说明实际样本并非线性分类问题，则选择使用核函数将原空间的数据映射到新空间，然后在新空间中用线性方法进行学习，常用核函数有线性核，多项式核，高斯核 (RBF核) 等，其中，使用高斯核，并结合泰勒展开公式可将原样本数据映射至无穷维空间. 

 

### **评价指标**

对于二分类问题，我们通常将精确率 (precision) 与召回率 (recall) 作为评价指标. 将违约类记为正类，未违约类记为负类，则分类器在测试集上的预测与实际类别之间有如下四种情况，即混淆矩阵：

<center> <font size = 2>表2. 1 混淆矩阵</font></center>

| 实际\预测 | Positive | Negative |
| :-------: | :------: | :------: |
|   正类    |    TP    |    FN    |
|   负类    |    FP    |    TN    |

TP 代表正类预测结果为正类数，FN 代表正类预测结果为负类数，FP 代表负类预测结果为正类数，TN 代表负类预测结果为负类数. 定义精确率 P 和召回率 R 分别为：
$$
P=\frac{TP}{TP+FP}\\R=\frac{TP}{TP+FN}\tag{2.24}
$$
为了比较不同分类器性能的优劣，人们引入 $F1$ 值来进行综合衡量精确率与召回率.  $F1$ 是 $P,\ R$ 的调和平均：
$$
\frac{2}{F1}=\frac{1}{P}+\frac{1}{R}\\F1=\frac{2TP}{2TP+FP+FN}\tag{2.25}
$$
而分类准确率 (accuracy) 指测试集中样本正确分类数与样本总数之比，即
$$
ACC=\frac{TP+TN}{TP+FP+FN+TN}\tag{2.26}
$$



## **三、数据来源和处理**

### **数据来源**

[人人贷](https://www.renrendai.com/)是 P2P 网络信贷平台中较资深的一个，已于 2018 年 07 月 10 日加入中国互联网金融协会任常务理事单位. 本文选择从人人贷网站入手，获取其公开的散标数据. 散标是网贷平台根据借款人的申请在网站发布的招标信息，投资者 ( 或称贷款人 ) 视情况将自己多余的钱款进行投标，标满后意味着借贷关系成立，借款人需按时或提前还付既定本息. 

经过查阅，近两年人人贷发布的散标多数仍在还款中，而 2016 年初发布的散标都已在 2019 年或之前经过了结算，因此本文选择该时间段前后的散标数据进行收集. 我们从散标号为 NO. 736666 至 NO. 808545 和 NO. 2000002 至 NO. 2036666 的 108545 个借贷交易数据中检索得到散标状态为 “ BAD_DEBT ” 的 575 条数据，其余数据的散标状态绝大多数为 “ CLOSED ” 和 “ FAILED ”，以 “ CLOSED ” 居多，其中状态 “ BAD_DEBT ” 代表借款人已违约，“ CLOSED ” 代表借款人已按时还清借款本息，而 “ FAILED ” 代表散标已流标、借贷交易未成功，并不在本文研究范围内. 显然，违约数据与未违约（按时还清）数据数量差距很大，属于类别严重不平衡，若直接进行学习可能导致较大误差，甚至可能由于数量太少被当做噪声处理. 因此我们选择欠采样方法，从上述散标范围中随机抽取了 1200 条未违约数据. 经过筛选，剔除缺失值较多的样本，最终得到了违约与未违约比例为 1:2  的数据样本集，其中违约数据 571 条，未违约数据 1155 条，总计 1726 条数据. 

 

### **数据处理**

经过人工筛除部分无关变量，本文获取得到的散标记录中包含散标状态，散标总额，年利率，还款期限，性别，年龄，婚姻，房产，房贷，车产，车贷，申请借款，成功借款，还清笔数，信用额度，逾期次数，严重逾期等共 26 个变量，其中，散标状态是各个样本的类别标记，各变量类型及相关数据处理见表 3. 1. 然后计算各个变量的均值与方差，方差过小，则没有加入模型的必要，只会徒增学习过程的复杂度，因此将方差很小的变量剔除，如：车贷、其他负债. 

<center> <font size = 2>表3. 1 变量对照表</font></center>

![image-20210228141028915](C:\Users\叶隽宇\AppData\Roaming\Typora\typora-user-images\image-20210228141028915.png)

经过初步分析，我们发现：第一，待还本息截止目前仍大于 0 的散标，除去少数几个外，基本上都是违约状态，逾期金额同样如此；第二，散标状态与风险等级密切相关，风险等级是以平台用户信誉度为标准评定的，用户信誉越低，风险等级越高，该次交易违约可能性越大. 那么，是否其它变量间也存在相关性？本文选择通过计算样本的协方差矩阵与 Pearson 相关系数来检验任意两个变量间的线性相关性. 相关系数是对协方差的进一步处理，取值在 $[1,\ -1]$，相关系数绝对值越大，则说明对应的两个变量线性相关性越强. 本文将 26 个变量依照上述次序标为 $\beta_1,\ \beta_2,\ \beta_3,...,\beta_{26}$，通过使用 Python 第三方库 numpy 的 corrcoef( ) 函数可直接算出相关系数矩阵，将相关系数 $\rho$ 绝对值较大的筛选出来见表 3. 2，两个变量间相关性越强，则意味着两个变量代表的信息重复越多，可以剔除其中一个以减少样本特征数. 

<center> <font size = 2>表3. 2 相关系数表</font></center>

![image-20210228120624839](C:\Users\叶隽宇\AppData\Roaming\Typora\typora-user-images\image-20210228120624839.png)

从表中不难看出，变量 $\beta_1,\ \beta_6,\ \beta_{26}$ 两两线性相关，$\beta_{25}$ 与 $\beta_1,\ \beta_4,\ \beta_{6}$ 和 $\beta_{26}$ 密切相关，$\beta_{2}$ 与 $\beta_{22}$、$\beta_{23}$与 $\beta_{24}$ 密切相关，其中，$\beta_{1}$是类别标记，不应删除. 因此，综上所述，我们选择在样本变量集中去除$\beta_2,\ \beta_6,\ \beta_{23},$ $\ \beta_{24},$$\ \beta_{25}$ 和 $\beta_{26}$，即散标总额，风险等级，待还本息，逾期金额，逾期次数和严重逾期，最终得到了有18个变量的数据样本集，包含：散标状态，借款原因，年利率，还款期限，性别，年龄，婚姻，收入，工作时间，学历，房产，房贷，车产，申请借款，成功借款，还清笔数，信用额度，借款总额. 

进一步地，对借贷人信息进行分析，如图 3.1，我们发现数据集中 2015 年 9 月至 2016 年 6 月的借贷人大多数为男性(76.65%)，仅 23.35% 为女性. 年龄以 30-50 岁的中年客户居多，少量青少年与老年. 在婚姻状况方面，65.99% 的用户已婚，25.14% 未婚，8.57% 离异，其余为丧偶. 借贷人的收入水平也参差不齐, 1001-2000 元的占0.23%，2000-10000 元的客户占据了大多数，高达 70.74%，收入 10000 元以上的占 29.03%. 至于工作时长，工作了 1 年 (含) 以下的用户占比 20.10%，1-3 年 (含) 的占 26.71%，3-5 年 (含) 的占 13.90%，工作长达 5 年以上的占比最高，为 39.28%. 在借款原因中，以短期周转，个人消费居多，占比 69.7%，购车借款最少，仅占 2.5%. 借款金额从数百至数万不等，还款期限则大多大于 12 月以上.

![image-20210228114900165](C:\Users\叶隽宇\AppData\Roaming\Typora\typora-user-images\image-20210228114900165.png)

<center> <font size = 2>图 3.1 借贷人各项信息饼状图</font></center>



## **四、实证分析**

### **PCA**

在开始测试具体模型之前，我们尝试着对数据样本集进行了一次主成分分析 ( Principal Component Analysis，简称 PCA )，发现了一个有趣的现象. 在前两个主成分的累计方差贡献率超过 98% 的前提下，我们将样本维度降至了二维，并将数据样本在该二维坐标系上的投影可视化，得到了下图：

![image-20210228114924631](C:\Users\叶隽宇\AppData\Roaming\Typora\typora-user-images\image-20210228114924631.png)

<center> <font size = 2>图4. 1 PCA降维图</font></center>

由于前两个主成分的方差贡献率远超其他成分贡献率之和，我们可以认为这两个成分蕴含了数据样本的绝大部分信息量，整个样本集的分布几乎可以在这两个成分对应的维度中体现出来，也就是说，样本集在这两个维度下的投影分布可以近似反映所有样本在 17 维(不含类别标记)的高维特征空间中的分布. 我们发现在这种“无监督式”降维后，大多数样本在新坐标系下形成两条明显的线性关系. 这是否意味着我们也许能尝试用线性模型去拟合样本集并可能会取得良好效果? 基于这一启发，接下来的模型选择我们优先考虑线性分类器. 

 

### **模型应用**

本文采用十折交叉验证，并进行分层采样，将数据集分为十个互不相交的大小相同的子集，每个子集中违约与未违约之比仍为 1:2，对每一种算法共进行十次学习，每次选择一个不同子集作为测试集，其余九个作为训练集. 训练集中数据用作输入信息，是提供给计算机分析的素材，获得充分数据后，系统可以归纳总结样本与所属分类间的微妙联系和规律，建立分类模型. 测试集则将自身样本数据输入模型，并将样本实际类别与模型预测结果进行对比，进而评估模型的性能. 每次学习的训练集包含样本约 1553 个，测试集包含样本约 173 个，且每次训练前，用 Python 语言 sklearn 库的 StandardScaler( ) 将训练数据与测试数据分别进行标准化. 最后从十次模型结果中计算平均测试误差作为该算法最终模型精度的估计. 

 

#### **线性判别分析**

首先我们选择与PCA思想接近的线性判别分析 LDA 进行拟合. 我们试图将所有样本点投影至一条直线上，根据直线上投影点的离散聚合程度进行分类，如果两个类别间隔较大、边界清晰，则 LDA 可取得良好分类效果. 在交叉验证分割子集后，对训练集中的相应数据进行 LDA，并对测试集进行相同变换. 以第一次学习得到的模型为例，结果如图 4. 2 所示. 图 a, b, c分别表示 LDA 处理后的训练集，测试集和测试集预测结果. 黄色代表实际违约类，紫色代表实际未违约类，横坐标对应数据集的样本经过 LDA 映射至一维直线上的投影坐标值，纵坐标对应样本实际或预测的类别标记 $y$ ( 0 为未违约，1 为违约 ). 

​                             ![image-20210228115453941](C:\Users\叶隽宇\AppData\Roaming\Typora\typora-user-images\image-20210228115453941.png) 

<center> <font size = 2>图4. 2 第一次LDA模型</font></center>

对比图b，图c，可以发现，LDA 只对横坐标为 $X_1=1.52778601$ 和 $X_2=2.03142837$ 两点的分类出现了错误，总体性能比较好. 进行十次学习后，我们将各模型的测试结果求平均值得到了表4. 1，相应地，由十次 LDA 模型结果得到各指标平均值：精确率为 0. 965，召回率为 1. 000，F1值为 0. 982，分类准确率为 0. 988，AUC 为 0. 999. 

<center> <font size = 2>表4. 1 LDA混淆矩阵</font></center>

|  实际\预测   | 正类  |  负类  |
| :----------: | :---: | :----: |
|  正类(违约)  | 57. 1 |  0. 0  |
| 负类(未违约) | 2. 1  | 113. 4 |

分析结果，我们可以发现，LDA 模型对于违约样本的分类准确率很高，可以正确地将违约样本归为正类. 此外，注意到预测结果为负类的样本都属于未违约类，因而我们可以一定程度上认定预测为负类的用户有极大概率不会违约. 另一方面，尽管 LDA 将样本维度降至了一维，但是过程中产生的那条直线是某些特征的线性组合，现实生活中没有清晰的意义. 而且，不同于 Logistic 回归在整个空间上将样本点分割为两类，LDA 是对直线上的投影点根据位置进行分类，不易理解组合出直线的那些特征对分类如何起作用，并不利于进一步对模型进行分析和优化. 

 

#### **决策树**

为了知道各个变量对样本分类的权重与作用，本文选择使用决策树直观地体现具体的机器学习过程. 决策树是个递归的过程，每次递归找到一个当前最优划分，算法期望通过局部最优逐步逼近全局最优，进而获得理想的分类效果. 

在三个经典决策树算法中，C4. 5 的信息增益比计算最为复杂，算法效率相对较低，数据集规模越大这一缺点越明显，因此本文仅采用其他两种算法进行模型训练. 我们使用 sklearn 库中 DecisionTreeClassifier( ) 函数进行学习，得到的 ID3 和 CART 的混淆矩阵差别不大，各项指标平均值比较如下：

<center> <font size = 2>表4. 2  两种决策树的性能比较</font></center>

|              | ID3决策树 |        |              | CART决策树 |        |
| :----------: | :-------: | :----: | :----------: | :--------: | :----: |
|  实际\预测   |   正类    |  负类  |  实际\预测   |    正类    |  负类  |
|  正类(违约)  |   56. 6   |  0. 5  |  正类(违约)  |   56. 4    |  0. 7  |
| 负类(未违约) |   0. 3    | 115. 2 | 负类(未违约) |    0. 5    | 115. 0 |

|      | 函数参数 | 精确率 | 召回率 |   F1   | 准确率 |  AUC   |
| :--: | :------: | :----: | :----: | :----: | :----: | :----: |
| ID3  | entropy  | 0. 995 | 0. 991 | 0. 993 | 0. 995 | 0. 996 |
| CART |   gini   | 0. 991 | 0. 988 | 0. 990 | 0. 993 | 0. 988 |

经过对比，ID3 算法略占优势，四项指标都高于 CART. 下图所示是十折交叉验证中第一棵 ID3 决策树的生成过程(未进行数据标准化)，为防止过拟合，将参数 min_samples_split ( 结点再划分所需最小样本数 ) 置为 12，min_impurity_decrease ( 结点再划分所需不纯度减小量的最小值 ) 置为 0. 005，颜色深浅反映所属类别纯度高低，value 表示未违约类与违约类在该结点中分别有多少. 

​                              ![image-20210228115115471](C:\Users\叶隽宇\AppData\Roaming\Typora\typora-user-images\image-20210228115115471.png) 

<center> <font size = 2>图4. 3  第一棵ID3决策树</font></center>

根据上图并结合表 3. 1可知，还款期限、年利率、还清笔数、信用额度和成功借款 5 个变量对该决策树的生成有重要作用，其余变量并未参与树的分支过程. 通常而言，决策树各个划分变量的重要性自顶向下依次递减，由此我们可以判断还款期限与借款人是否违约紧密相关，影响最大，其次是年利率，综合二者，可以认为，对于还款期限小于等于 30 月且年利率大于 10. 9% 的客户有很大概率会违约. 同时，注意到该树左子树的右子树较高，可能依旧存在过拟合，实际应用中可考虑进一步的剪枝处理. 

通过十折交叉验证的决策树算法，对十棵 ID3 树进行比对，我们发现，还款期限、年利率、还清笔数、成功借款、信用额度和申请借款等 6 个特征在违约预测当中起到了作用，我们使用 DecisionTreeClassifier 的属性 feature_importances_ 算出了各变量重要性平均为：0. 6949、0. 1801、0. 0597、0. 0388、0. 0242 与 0. 0023. 显然，还款期限在分类预测中起到了无可争议的最大作用，其次年利率对违约的判别也有效果，应特别注重还款期限小于等于 30 月且年利率大于 10. 9% 的借款客户，他们有较大的违约可能；还清笔数、成功借款、信用额度和申请借款也有一定影响，相关机构应综合考虑. 而其他的 11 个特征对违约的影响则很小，可以不予优先考虑. 

决策树直观，易于理解与实现，且对缺失值不敏感，诸多优点使其得到了广泛应用. 同时，值得一提的是，无论是  ID3、C4. 5 还是 CART 算法，结果都不够稳定，数据的些许变化可能会导致形成不同的树，故而通常使用集成学习来增强决策树的抗噪声能力. 另外，对类别不平衡的数据会产生偏向性也是决策树的掣肘之一. 

 

#### **支持向量机**

LDA 将样本直接降至一维，尽管可以直观观测到样本投影的一维分布，但多少会造成一定程度的数据失真；决策树可以清晰表现在整个树形成过程中各个特征起到的分类作用，但若想从所有可能的决策树中找到最优决策树是NP完全问题，需要列举所有决策树，计算量很大，因而通常的算法基于贪心策略选择近似求解，找到次最优的决策树. 而 SVM 平衡了两者的不足，在保持样本原有分布的前提下，根据全部的数据进行分析，通过求解二次规划问题，以期获得全局最优解. 

SVM 的目标是在特征空间中找到一个超平面将样本按类别分割，并使得两类样本到超平面距离尽可能大. 我们选择使用 sklearn 库的 SVC() 函数进行学习. SVC() 中参数 kernel 默认为 RBF 核函数，而由之前 PCA 的启发，也许线性分类器效果不错，于是我们将参数设置为线性核后，再进行了一轮交叉验证，得到最终结果：

<center> <font size = 2>表4. 3 不同核函数SVM比较</font></center>

|              | RBF核混淆矩阵 |        |              | 线性核混淆矩阵 |        |
| :----------: | :-----------: | :----: | :----------: | :------------: | :----: |
|  实际\预测   |     正类      |  负类  |  实际\预测   |      正类      |  负类  |
|  正类(违约)  |     57. 0     |  0. 1  |  正类(违约)  |     57. 0      |  0. 1  |
| 负类(未违约) |     0. 7      | 114. 8 | 负类(未违约) |      0. 1      | 115. 4 |

|        | 精确率 | 召回率 |   F1   | 准确率 |  AUC   | 支持向量数 |
| :----: | :----: | :----: | :----: | :----: | :----: | :--------: |
| RBF核  | 0. 988 | 0. 998 | 0. 993 | 0. 995 | 0. 999 |  224. 6个  |
| 线性核 | 0. 998 | 0. 998 | 0. 998 | 0. 999 | 0. 999 |  21. 3个   |

从表中可以看出，二者召回率基本相同，AUC 也近似达到 1，但对于负类样本的预测，后者的分类要比前者更准确. 对比多方面指标，可以认为线性模型分类效果确实优于 RBF 核模型. 此外，线性 SVM 的各项指标也大多优于上述其他模型，是目前为止最理想的、综合性能最高的模型. 我们对线性 SVM 进一步地分析，发现数据标准化后，其样本特征空间的超平面各个变量的系数平均为

<center> <font size = 2> 表4. 4  超平面各变量系数 </font> </center> 

|   变量   |    系数    |   变量   |    系数    |   变量   |    系数    |
| :------: | :--------: | :------: | :--------: | :------: | :--------: |
| 借款原因 | -0. 016758 |   收入   | 0. 041773  | 申请借款 | 0. 178460  |
|  年利率  | 0. 609591  | 工作时间 | 0. 057560  | 成功借款 | 1. 489258  |
| 还款期限 | -0. 821193 |   学历   | 0. 001608  | 还清笔数 | -1. 817562 |
|   性别   | 0. 004301  |   房产   | -0. 075343 | 信用额度 | -0. 243178 |
|   年龄   | 0. 044288  |   房贷   | 0. 004689  | 借款总额 | -0. 032549 |
|   婚姻   | -0. 044103 |   车产   | 0. 016474  |          |            |

样本的 17 个特征都参与了超平面的生成，其中性别、学历、房贷等 3 个变量系数最小，其观测值的波动对最终结果产生的扰动很小，换句话说，这 3 个特征对是否违约的区分度不显著，分类作用很小. 而还清笔数、成功借款、还款期限和年利率系数最大，对于超平面划分有较大影响. 

SVM 模型固然性能很好，但潜在缺点也有数个. 首先，超平面参数的计算涉及所有的样本数据，训练模型之前，需对所有数据进行全面标注；其次，SVM 适用于二分类任务，对于多分类问题需要将其拆分为多个二分类进行求解；另外，其直观性不如决策树，超平面更加抽象，模型分类依据不易解释；最后，SVM 求解二次规划的过程中，涉及样本数 $m$ 阶矩阵的计算，耗费内存资源较多，不适合处理大规模数据样本. 

 

#### **LDA算法改进**

对比三个模型，我们发现，决策树与 SVM 算法表现良好，LDA 算法相较之下性能欠佳. 然而，LDA 却有一个优势，实现了在十次交叉验证中对正类样本预测的零失误，我们是否可以在保持这一特性的前提下提升 LDA 的其他性能呢？

我们重新对 LDA 过程及其预测结果进行分析：首先对训练集样本标准化后，用 LDA 将样本维数降至 1，所有样本点便分布在了一条直线上. 为便于理解，我们将十折交叉验证产生的十个模型对各自测试集的预测结果显示如下，黄色代表实际违约类，紫色代表实际未违约类，横坐标对应测试集的样本经过 LDA 映射至一维直线上的投影坐标值，纵坐标对应模型预测的类别标记 $y$ ( 0 为负类，1 为正类 ). 

​                            ![image-20210228115213735](C:\Users\叶隽宇\AppData\Roaming\Typora\typora-user-images\image-20210228115213735.png) 

<center> <font size = 2>图4. 4  十折交叉验证LDA预测图</font></center>

从图中可以看出，在每次训练集、测试集都不同的情况下，LDA 只是将位于两类边界处的未违约样本点错误预测为了正类，而对违约类的召回率则达到了 100%. 那么，如果我们能在直线上两类的边界区域附近找到一个阈值 $\varepsilon$，将所有大于阈值 $\varepsilon$ 的样本投影点预测为正类，否则预测为负类，是否可以提升 LDA 的精度呢？我们将原本高维样本二分类问题转换成了一维直线上重新寻找划分点的问题. 本文尝试找到一个能提高模型精度的可行解 $\varepsilon$ . 通过比较图 4. 4，可以发现实际上只需在所有预测为正类的样本中找到一个能将黄色点全部正确分类，并尽可能将紫色点分为负类的点. 为方便进一步分析，我们将每一个图中所有 $y\_predict=1$ 的紫色点的横坐标最大值 $Max\_0$ 与所有 $y\_predict=1$ 的黄色点的横坐标的最小值 $Min\_1$ 标注出(若紫色点全部分类正确则 $Max\_0= 0 $ )：

<center> <font size = 2>表4. 5 Max_0与Min_1</font></center>

|   序号   |     1     |     2     |     3     |     4     |     5     |
| :------: | :-------: | :-------: | :-------: | :-------: | :-------: |
|  Max_0   | 2. 797987 | 2. 362996 | 2. 297564 | 4. 140052 | 1. 766931 |
|  Min_1   | 4. 402662 | 2. 109285 | 2. 116322 | 4. 596135 | 4. 386957 |
| **序号** |   **6**   |   **7**   |   **8**   |   **9**   |  **10**   |
|  Max_0   | 2. 420875 |     0     |     0     | 1. 605299 |     0     |
|  Min_1   | 3. 236017 | 3. 593514 | 3. 656769 | 4. 235056 | 3. 361579 |

为保证高召回率且具有一定的泛化能力，阈值 $\varepsilon$ 应在小于等于 $Min\_1$ 中最小项的前提下尽可能的小；同时为了使紫色点尽可能少的被分到正类，阈值 $\varepsilon$ 不能太小，这里我们选取十个 $Max\_0$ 的算数平均 $\mu$ 作为 $\varepsilon$ 的一项指标，即：

当 $min\ Min\_1<\mu$ 时， $\varepsilon = min\ Min\_1$；

当 $min\ Min\_1\geq\mu$ 时，取 $\varepsilon$ 为 $min\ Min\_1$ 与 $\mu$ 的中点
$$
\varepsilon = \frac{1}{2}(min\ Min\_1+\mu).
$$
结合表 4. 5数据，求得 $\mu=1.739170,\ min\ Min\_1=2.109285$，取 $\varepsilon=1.924$ . 使用 $\varepsilon$ 进行分类后结果如下

​                            ![image-20210228115400906](C:\Users\叶隽宇\AppData\Roaming\Typora\typora-user-images\image-20210228115400906.png) 

<center> <font size = 2>图4. 5 改进后预测结果</font></center>

可以发现，改进后 LDA 的分类效果明显增强，错误样本数明显减少. 因此，该算法是可行的. 但上述过程中预测结果与实际样本类别的对比使用了测试集数据的类别标记，现实预测中是无法预先知道待测样本具体类别的，不应令测试集的数据参与模型训练的过程，因而算法应稍加改动为如下过程：

1. 将整个数据集按一定比例拆分为训练集与测试集；

2. 对训练集使用 K 折交叉验证，即将训练集拆分 K 份，训练出 K 个 LDA 模型；

3. 找出每个模型的 $Max\_0$ 与 $Min\_1$，进而计算出阈值 $\varepsilon$；

4. 用整个训练集数据生成新的 LDA 模型，得到投影直线 $\omega$；

5. 将测试集的样本点投影至直线 $\omega$上；

6. 用阈值 $\varepsilon$ 对样本投影点进行分类. 

我们用新算法将数据集按 9:1 随机分为训练集与测试集，并对训练集进行十折交叉验证，将求得的阈值 $\varepsilon$ 用于对测试集分类，最终结果如表 4. 6. 

<center> <font size = 2>表4. 6 改进算法的混淆矩阵</font></center>

|              | 改进 LDA 算法 |        |
| :----------: | :-----------: | :----: |
|  实际\预测   |     正类      |  负类  |
|  正类(违约)  |     57. 0     |  0. 0  |
| 负类(未违约) |     1. 0      | 115. 0 |

模型精确率为 0. 983，召回率为 1. 000，F1值为 0. 991，准确率为 0. 994，各项指标都较原 LDA 有所提高. 不过，该算法虽然可以在保持原 LDA 高召回率的基础上，提升其他各项精度，但是阈值的求解主要通过计算机实现，并不能得到具体的数学表达式，更重要的是，算法仅适用于特定数据集，对于更宽泛的数据来源，有效性仍有待验证.  

 

### **模型性能对比**

本文先后使用了 LDA、决策树、SVM 和改进的 LDA 算法训练模型，各项指标表现优良，取得了较好的分类效果. 在得到了 3 种主要模型后，需要对各个模型进行综合评价，以遴选出适合实际问题的最优模型. 结合 2. 4 模型评价指标，现将各个模型精确率，召回率，F1，准确率比较如下：

<center> <font size = 2>表4. 7 各模型性能比较</font></center>

|  模型名称  | 精确率 | 召回率 |   F1   | 准确率 |
| :--------: | :----: | :----: | :----: | :----: |
|    LDA     | 0. 965 | 1. 000 | 0. 982 | 0. 988 |
| ID3决策树  | 0. 995 | 0. 991 | 0. 993 | 0. 995 |
| CART决策树 | 0. 991 | 0. 988 | 0. 990 | 0. 993 |
|  RBF核SVM  | 0. 988 | 0. 998 | 0. 993 | 0. 995 |
| 线性核SVM  | 0. 998 | 0. 998 | 0. 998 | 0. 999 |
|  改进LDA   | 0. 983 | 1. 000 | 0. 991 | 0. 994 |

综上比较，LDA，决策树和 SVM 三种算法各有所长. LDA 胜在对违约样本进行分类的高正确率，但即便改进了算法，LDA 其他性能仍旧相对较低；决策树可以清晰展现决策过程与划分特征，但单棵树不稳定，数据的微小扰动会改变整体的结构；SVM 拥有很好的综合性能，各项指标表现优秀，但分类过程比较抽象，求解二次规划时需要耗费机器较多存储空间与计算时间. 

三种算法各有千秋，差距并不明显，总体而言，各项指标都表现很好，分类效果优良. 不过，本文研究的主要是如何能更准确的对借款人进行是否违约预测，期望可以正确找到所有违约客户. 尽管 LDA 模型可能将一个不违约客户误判为违约客户，但却有着很高的召回率，几乎不会将违约客户预测为不违约，能有效减少贷款机构的损失. 随着交易数量的增加，其他模型预测错误造成的损失不断增多，LDA 这一优势会越加明显. 因此，对 P2P 网贷机构而言，或许 LDA 模型是个更好选择. 同时我们也需要借鉴其他模型的结果，例如，从 SVM 中，我们了解到，性别、学历与房贷对是否违约影响很小，还清笔数、信用额度、还款期限和年利率影响较大，应当有针对性的关注. 而通过 ID3 决策树算法，本文发现，还款期限、年利率、还清笔数、成功借款、信用额度和申请借款等 6 个特征在对于人人贷数据的违约预测当中起到了作用，应特别注重还款期限小于等于 30 月且年利率大于 10. 9% 的借款客户，他们有较大的违约可能. 

尽管 SVM、决策树综合性能更好，但是由于违约才是实际生活中更加注重的问题，因此，本文认为，改进后的 LDA 模型更加适合处理网贷违约预测问题. 而在借贷过程中，需要多加注意还款期限、年利率、还清笔数等因素. 



## **五、总	结**

本文基于前人的研究成果，通过人人贷网贷平台的数据，对借款人是否会违约进行了预测，先后使用了 LDA、决策树与 SVM 三种算法训练预测模型，并针对 LDA 算法进行了尝试性改进，经过各项指标权衡，最终选择改进后的 LDA 算法作为最优模型. 

在训练模型的过程中，本文得到了如下结论：

1. 经过多个模型拟合数据、对比结果，从精确度，召回率，F1值，准确率各方面考量，结合网贷实际情况，本文认为改进的 LDA 模型更加适合处理贷款违约预测问题. 

2. 根据决策树及 SVM 训练结果，我们发现还款期限、年利率、还清笔数、信用额度等特征对违约预测有相当程度的影响，特别是期限三年以内，年利率较高的贷款较容易发生违约. 与之相反，性别、学历和房贷的影响很小. 相关人员可以加以关注、借鉴. 

3. SVM 整体性能最佳，对于更加重视模型总体指标的机构或者借贷交易量较少的小型网贷机构可以优先考虑选择线性 SVM 进行相应业务预测. 

本文各个模型取得较高精度的原因：

1. 在数获取的过程中，本文使用了爬虫从平台官网采集样本，官方公布的数据经过了平台方面的必要处理，使得数据更加规整. 

2. 样本多数特征在经过初步筛选后，本身便与个人财务有着直接相关性，与客户是否借贷、会否违约有较强关联. 

3. 训练模型前对数据进行了标准化，使得各个特征的权重相对均衡，不会因为某些特征在初始数据样本中比重更大而影响了其他特征的分类作用. 

纵观整个研究过程，本文也存在以下不足：

1. 采集的样本数量较少，噪声对模型有一定程度的影响，训练过程中可能将噪声的特点也学入了模型，影响最终结果. 

2. 虽然使用十折交叉验证尽可能的减少了模型的偶然性与意外性，但对于是否存在过拟合问题，本文未进行深入探查. 

3. 在使用 LDA 与 SVM 相关算法时，需要各个特征之间是相互独立的，而本文在默认样本数据满足这一条件的基础上进行了相关训练，虽然最终结果良好，但过程并不严谨. 文中没有进行特征非线性相关性的检测，我们无法断言散标样本的特征之间完全独立. 

4. 在决策树算法中，每一次交叉验证得到的树结构都不完全相同，即树不够稳定，可以使用随机森林或其他集成方法训练出更加稳定、准确的模型. 

对于本文使用的研究方法，事实上还有一些可以进一步提高模型精度的方法，比如利用决策树得到的 6 个划分变量结合 SVM 或 LDA 进行更细致的预测，但由于现有模型精度已足够，过于追求更高的性能看起来锦上添花，但耗费了资源却没有取得明显效果，实则画蛇添足，也有悖奥卡姆剃刀原理. 

随着科学的蓬勃发展，机器学习算法也在不断创新、完善，但不论如何变化，机器学习的初衷是不变的——利用机器强大的运算能力，结合恰当的计算方法更好地解决实际问题，造福人类社会. 基于这一理念，我们应具体问题具体分析，因地制宜，因时而定，不同的场合使用不同的算法，正确灵活地运用算法解决实际问题，才能让机器学习在人们生活中大放异彩. 



## **参考文献**

[1]  陈雪. P2P网贷存在问题及发展对策研究[D]. 河南科技大学,2018. 

[2]  李航. 统计学习方法[M].  北京: 清华出版社.  2012. 

[3]  李学燕. 组合模型在网络借贷反欺诈中的应用研究[D]. 对外经济贸易大学,2018. 

[4]  李汛,龙真,付怀宇,刘品璐. 基于机器学习的P2P违约预测算法比较——以“人人贷”为例[J]. 统计与管理,2019(06):104-109. 

[5]  罗雅晨. 类别不平衡的集成学习预测P2P网贷信用风险[J]. 科技与创新,2018(24):1-4. 

[6]  马鸣宇. 基于机器学习的P2P网络借贷风险预测[D]. 华中科技大学,2018. 

[7]  倪伟岸. 人人贷借贷效率分析[D]. 南京大学,2016. 

[8]  汤璇. Logistic回归模型在P2P平台风险评估中的应用[J]. 湖北经济学院学报(人文社会科学版),2017,14(04):41-43. 

[9]  王梦雪. 基于机器学习技术的P2P风控模型研究[D]. 哈尔滨工业大学,2017. 

[10] 吴艇帆. 基于L1正则化Logistic回归模型的P2P网络贷款风险测度应用研究[D]. 广州大学,2019. 

[11] 夏雨霏,刘传哲,徐嘉辰. 聚类支持向量机在P2P网络借贷违约预测中的应用[C].  中国管理现代化研究会、复旦管理学奖励基金会. 第十届（2015）中国管理学年会论文集. 中国管理现代化研究会、复旦管理学奖励基金会:中国管理现代化研究会,2015:507-514. 

[12] 杨帆. 我国P2P网络借贷平台的风险控制与监管转型[J]. 现代商业,2018(13):88-89. 

[13] 张丽霞. 基于机器学习算法的网络借贷信用风险预测模型研究[D]. 兰州大学,2019. 

[14] 郑志强. P2P网贷个人信用评分模型的研究[D]. 暨南大学,2016. 

[15] 周志华. 机器学习[M].  北京: 清华出版社.  2016. 

[16] Corinna Cortes, Vladimir Vapnik. Support-Vector Networks. [J]Machine Learning, 1995(20): 273-297. 

[17] Jing Zhou,Wei Li,Jiaxin Wang,Shuai Ding,Chengyi Xia. Default prediction in P2P lending from high-dimensional data based on machine learning[J]. Physica A: Statistical Mechanics and its Applications,2019,534. 

[18] Liu Chongming. Risk and Strategy Research on Peer to Peer network lending in China[C].  大连理工大学. 第八届（2016）金融风险与公司金融国际研讨会论文集. 大连理工大学:大连理工大学管理与经济学部经济学院,2016:280-285. 

[19] Netty Setiawan,Suharjito,Diana. A Comparison of Prediction Methods for Credit Default on Peer to Peer Lending using Machine Learning[J]. Procedia Computer Science,2019,157. 

[20] Ryan Randy Suryono,Betty Purwandari,Indra Budi. Peer to Peer (P2P) Lending Problems and Potential Solutions: A Systematic Literature Review[J]. Procedia Computer Science,2019,161. 

 



 
